services:
  proxy:
    image: nginx:1.25
    container_name: mirs-proxy
    ports:
      - "8080:80"
    volumes:
      - ./.dev/data:/usr/share/nginx/data
      - ./.dev/nginx/nginx.conf:/etc/nginx/conf.d/default.conf
  
  redis:
    image: 'bitnami/redis:latest'
    container_name: mirs-redis
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '6379:6379'

  kafka:
    image: 'bitnami/kafka:3.6.0'
    container_name: mirs-kafka
    ports:
      - '9092:9092'
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@localhost:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
  pg:
    image: 'mirs/pgvector'
    container_name: mirs-db
    ports:
      - '5432:5432'
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=085410
      # - POSTGRES_DB=postgres
    volumes:
      - ./.dev/database/init-user-db.sh:/docker-entrypoint-initdb.d/init-user-db.sh

  pgadmin:
    image: 'dpage/pgadmin4'
    container_name: mirs-pgadmin
    ports:
      - '5050:80'
    environment:
      - PGADMIN_DEFAULT_EMAIL=kevin@mirs.ai
      - PGADMIN_DEFAULT_PASSWORD=085410
    depends_on:
      - pg

  # Mac has trouble supporting GPU in docker, we have to run ollama alongside docker
  # ollama:
  #   image: 'ollama/ollama'
  #   container_name: mirs-ollama
  #   pull_policy: always
  #   restart: always
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   ports:
  #     - '11434:11434'
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0

  chat:
    image: 'ghcr.io/open-webui/open-webui:main'
    container_name: mirs-chat
    ports:
      - '8888:8080'
    volumes:
      - chat-data:/app/backend/data
    environment:
      - WEBUI_AUTH=False
      - WEBUI_NAME=MIRS Chat
      - WEBUI_SECRET_KEY=085410
    restart: unless-stopped
    # depends_on:
    #   - ollama
  
volumes:
  # ollama-data:
  chat-data: